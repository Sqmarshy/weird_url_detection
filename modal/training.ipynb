{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "db1c55be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "521822b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(\"dataset_phishing.csv\")\n",
    "\n",
    "# Selecting features and target\n",
    "X = data.drop(columns=['url', 'status'])  # Drop non-numerical and target column\n",
    "y = data['status']  # Target column\n",
    "\n",
    "# Encoding the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Standardizing the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "random_seed = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_encoded, test_size=0.2, random_state=random_seed, stratify=y_encoded\n",
    ")\n",
    "\n",
    "# Converting to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Creating DataLoader for batch processing\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "82c414b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhishingDetectionModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(PhishingDetectionModel, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.35),  \n",
    "            nn.Linear(hidden_size, hidden_size // 2),  # Reduce neurons in second layer\n",
    "            nn.BatchNorm1d(hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size // 2, output_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Model parameters\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 64\n",
    "output_size = len(label_encoder.classes_)\n",
    "\n",
    "model = PhishingDetectionModel(input_size, hidden_size, output_size)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=0.01)  # L2 regularization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5a3224e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs, save_path):\n",
    "    best_f1 = 0.0  # Track the best F1 score\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "\n",
    "        # Training phase\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Collect predictions and true labels for F1 score and accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_labels.extend(y_batch.numpy())\n",
    "            all_preds.extend(predicted.numpy())\n",
    "        \n",
    "        # Calculate F1 score and accuracy for the epoch\n",
    "        epoch_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "        epoch_accuracy = accuracy_score(all_labels, all_preds)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}, \"\n",
    "              f\"F1 Score: {epoch_f1:.4f}, Accuracy: {epoch_accuracy:.4f}\")\n",
    "\n",
    "        # Evaluation phase\n",
    "        model.eval()\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in test_loader:\n",
    "                outputs = model(X_batch)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                # Collect predictions and true labels for F1 score and accuracy\n",
    "                all_labels.extend(y_batch.numpy())\n",
    "                all_preds.extend(predicted.numpy())\n",
    "        \n",
    "        # Calculate F1 score and accuracy\n",
    "        f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "        print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "        print(f\"Test F1 Score: {f1:.4f}\")        \n",
    "\n",
    "        # Save the model if it performs better\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_epoch = epoch\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"New best model saved with F1 Score: {f1:.4f} at epoch {epoch}\")\n",
    "\n",
    "    print(f'Best modal saved at epoch {best_epoch} with F1 score of {best_f1}')\n",
    "# Parameters for training\n",
    "num_epochs = 30\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "save_path = \"best_model.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "60eeb68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 0.2883, F1 Score: 0.8902, Accuracy: 0.8903\n",
      "Test Accuracy: 93.70%\n",
      "Test F1 Score: 0.9370\n",
      "New best model saved with F1 Score: 0.9370 at epoch 0\n",
      "Epoch 2/30, Loss: 0.1692, F1 Score: 0.9389, Accuracy: 0.9389\n",
      "Test Accuracy: 94.23%\n",
      "Test F1 Score: 0.9422\n",
      "New best model saved with F1 Score: 0.9422 at epoch 1\n",
      "Epoch 3/30, Loss: 0.1527, F1 Score: 0.9442, Accuracy: 0.9442\n",
      "Test Accuracy: 94.49%\n",
      "Test F1 Score: 0.9449\n",
      "New best model saved with F1 Score: 0.9449 at epoch 2\n",
      "Epoch 4/30, Loss: 0.1488, F1 Score: 0.9486, Accuracy: 0.9486\n",
      "Test Accuracy: 94.93%\n",
      "Test F1 Score: 0.9493\n",
      "New best model saved with F1 Score: 0.9493 at epoch 3\n",
      "Epoch 5/30, Loss: 0.1405, F1 Score: 0.9488, Accuracy: 0.9488\n",
      "Test Accuracy: 94.53%\n",
      "Test F1 Score: 0.9453\n",
      "Epoch 6/30, Loss: 0.1420, F1 Score: 0.9483, Accuracy: 0.9483\n",
      "Test Accuracy: 95.10%\n",
      "Test F1 Score: 0.9510\n",
      "New best model saved with F1 Score: 0.9510 at epoch 5\n",
      "Epoch 7/30, Loss: 0.1348, F1 Score: 0.9510, Accuracy: 0.9510\n",
      "Test Accuracy: 95.32%\n",
      "Test F1 Score: 0.9532\n",
      "New best model saved with F1 Score: 0.9532 at epoch 6\n",
      "Epoch 8/30, Loss: 0.1272, F1 Score: 0.9541, Accuracy: 0.9541\n",
      "Test Accuracy: 95.54%\n",
      "Test F1 Score: 0.9554\n",
      "New best model saved with F1 Score: 0.9554 at epoch 7\n",
      "Epoch 9/30, Loss: 0.1296, F1 Score: 0.9540, Accuracy: 0.9540\n",
      "Test Accuracy: 95.41%\n",
      "Test F1 Score: 0.9541\n",
      "Epoch 10/30, Loss: 0.1262, F1 Score: 0.9545, Accuracy: 0.9545\n",
      "Test Accuracy: 95.45%\n",
      "Test F1 Score: 0.9545\n",
      "Epoch 11/30, Loss: 0.1213, F1 Score: 0.9566, Accuracy: 0.9566\n",
      "Test Accuracy: 95.67%\n",
      "Test F1 Score: 0.9567\n",
      "New best model saved with F1 Score: 0.9567 at epoch 10\n",
      "Epoch 12/30, Loss: 0.1208, F1 Score: 0.9560, Accuracy: 0.9560\n",
      "Test Accuracy: 95.76%\n",
      "Test F1 Score: 0.9576\n",
      "New best model saved with F1 Score: 0.9576 at epoch 11\n",
      "Epoch 13/30, Loss: 0.1224, F1 Score: 0.9556, Accuracy: 0.9556\n",
      "Test Accuracy: 95.84%\n",
      "Test F1 Score: 0.9584\n",
      "New best model saved with F1 Score: 0.9584 at epoch 12\n",
      "Epoch 14/30, Loss: 0.1169, F1 Score: 0.9587, Accuracy: 0.9587\n",
      "Test Accuracy: 95.84%\n",
      "Test F1 Score: 0.9584\n",
      "Epoch 15/30, Loss: 0.1173, F1 Score: 0.9594, Accuracy: 0.9594\n",
      "Test Accuracy: 95.80%\n",
      "Test F1 Score: 0.9580\n",
      "Epoch 16/30, Loss: 0.1152, F1 Score: 0.9586, Accuracy: 0.9586\n",
      "Test Accuracy: 95.63%\n",
      "Test F1 Score: 0.9563\n",
      "Epoch 17/30, Loss: 0.1124, F1 Score: 0.9575, Accuracy: 0.9575\n",
      "Test Accuracy: 95.84%\n",
      "Test F1 Score: 0.9584\n",
      "Epoch 18/30, Loss: 0.1092, F1 Score: 0.9627, Accuracy: 0.9627\n",
      "Test Accuracy: 95.89%\n",
      "Test F1 Score: 0.9589\n",
      "New best model saved with F1 Score: 0.9589 at epoch 17\n",
      "Epoch 19/30, Loss: 0.1081, F1 Score: 0.9615, Accuracy: 0.9615\n",
      "Test Accuracy: 95.89%\n",
      "Test F1 Score: 0.9589\n",
      "New best model saved with F1 Score: 0.9589 at epoch 18\n",
      "Epoch 20/30, Loss: 0.1111, F1 Score: 0.9606, Accuracy: 0.9606\n",
      "Test Accuracy: 95.84%\n",
      "Test F1 Score: 0.9584\n",
      "Epoch 21/30, Loss: 0.1093, F1 Score: 0.9605, Accuracy: 0.9605\n",
      "Test Accuracy: 95.84%\n",
      "Test F1 Score: 0.9584\n",
      "Epoch 22/30, Loss: 0.1075, F1 Score: 0.9605, Accuracy: 0.9605\n",
      "Test Accuracy: 95.84%\n",
      "Test F1 Score: 0.9584\n",
      "Epoch 23/30, Loss: 0.1075, F1 Score: 0.9612, Accuracy: 0.9612\n",
      "Test Accuracy: 96.11%\n",
      "Test F1 Score: 0.9611\n",
      "New best model saved with F1 Score: 0.9611 at epoch 22\n",
      "Epoch 24/30, Loss: 0.1085, F1 Score: 0.9587, Accuracy: 0.9587\n",
      "Test Accuracy: 96.19%\n",
      "Test F1 Score: 0.9619\n",
      "New best model saved with F1 Score: 0.9619 at epoch 23\n",
      "Epoch 25/30, Loss: 0.1060, F1 Score: 0.9608, Accuracy: 0.9608\n",
      "Test Accuracy: 96.11%\n",
      "Test F1 Score: 0.9611\n",
      "Epoch 26/30, Loss: 0.0969, F1 Score: 0.9653, Accuracy: 0.9653\n",
      "Test Accuracy: 96.11%\n",
      "Test F1 Score: 0.9611\n",
      "Epoch 27/30, Loss: 0.1042, F1 Score: 0.9605, Accuracy: 0.9605\n",
      "Test Accuracy: 95.98%\n",
      "Test F1 Score: 0.9598\n",
      "Epoch 28/30, Loss: 0.1040, F1 Score: 0.9606, Accuracy: 0.9606\n",
      "Test Accuracy: 95.84%\n",
      "Test F1 Score: 0.9584\n",
      "Epoch 29/30, Loss: 0.1013, F1 Score: 0.9627, Accuracy: 0.9627\n",
      "Test Accuracy: 96.28%\n",
      "Test F1 Score: 0.9628\n",
      "New best model saved with F1 Score: 0.9628 at epoch 28\n",
      "Epoch 30/30, Loss: 0.0956, F1 Score: 0.9668, Accuracy: 0.9668\n",
      "Test Accuracy: 96.19%\n",
      "Test F1 Score: 0.9619\n",
      "Best modal saved at epoch 28 with F1 score of 0.9628167992059318\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f8234385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 96.28%\n",
      "Test F1 Score: 0.9628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leo88\\AppData\\Local\\Temp\\ipykernel_44308\\854269134.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_model.pth\"))\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        outputs = model(X_batch)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Collect predictions and true labels for F1 score and accuracy\n",
    "        all_labels.extend(y_batch.numpy())\n",
    "        all_preds.extend(predicted.numpy())\n",
    "\n",
    "# Calculate F1 score and accuracy\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Test F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ea755df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.0.weight, Shape: torch.Size([64, 87])\n",
      "tensor([[ 0.0830, -0.0645, -0.1006,  ...,  0.0512, -0.2791,  0.0336],\n",
      "        [-0.0550, -0.1966, -0.0790,  ..., -0.0518, -0.2835,  0.1668],\n",
      "        [ 0.0317,  0.1991, -0.0049,  ...,  0.0760,  0.1687, -0.3109],\n",
      "        ...,\n",
      "        [-0.2633,  0.1097, -0.0089,  ...,  0.1002,  0.1717, -0.2584],\n",
      "        [-0.0791, -0.0758, -0.0759,  ...,  0.0527, -0.2274,  0.0700],\n",
      "        [-0.0737,  0.0762, -0.1433,  ..., -0.0618, -0.0219,  0.2484]])\n",
      "Layer: model.0.bias, Shape: torch.Size([64])\n",
      "tensor([-0.0373, -0.0236, -0.1029,  0.0289,  0.0922, -0.0760, -0.0890, -0.0039,\n",
      "        -0.0154, -0.0137,  0.0940, -0.0688,  0.0258,  0.0375,  0.0122,  0.0642,\n",
      "        -0.0064,  0.0329, -0.0574,  0.0960, -0.0708, -0.0555,  0.0502, -0.1035,\n",
      "         0.0762, -0.0793, -0.0939, -0.0526, -0.0917, -0.0490,  0.0981, -0.0757,\n",
      "        -0.0094,  0.0409, -0.1114,  0.0966, -0.0503,  0.0908, -0.1036,  0.0896,\n",
      "         0.0910,  0.0313,  0.1004,  0.0675, -0.0939, -0.0087, -0.0370, -0.0867,\n",
      "        -0.0860,  0.0159, -0.0109, -0.0682,  0.0905, -0.0888,  0.0317,  0.0788,\n",
      "         0.0187, -0.0885,  0.0244,  0.0507, -0.0465,  0.0316, -0.0577,  0.0436])\n",
      "Layer: model.1.weight, Shape: torch.Size([64])\n",
      "tensor([1.0051, 1.0469, 0.9170, 0.9607, 0.9697, 0.9948, 0.9254, 0.9779, 0.9342,\n",
      "        0.9892, 0.9642, 0.8975, 1.0037, 0.9301, 0.9260, 1.0610, 0.9695, 0.9825,\n",
      "        0.9773, 0.9612, 0.9143, 0.9147, 0.9122, 1.0541, 1.0631, 0.9408, 0.9592,\n",
      "        0.9407, 0.9163, 0.9833, 0.9463, 0.9312, 1.0085, 0.9038, 0.9375, 0.9009,\n",
      "        0.9214, 0.9958, 0.8966, 1.0281, 0.9502, 0.9316, 0.9665, 0.9801, 0.9389,\n",
      "        0.9275, 0.9491, 0.9568, 0.8829, 0.9173, 0.9488, 0.9715, 0.8735, 0.9563,\n",
      "        0.9400, 0.9724, 0.9626, 0.9767, 0.8948, 0.9127, 0.9437, 0.9326, 1.0081,\n",
      "        0.9376])\n",
      "Layer: model.1.bias, Shape: torch.Size([64])\n",
      "tensor([-0.2162, -0.2222, -0.2103, -0.4555, -0.2996, -0.3983, -0.2380, -0.2912,\n",
      "        -0.2883, -0.2888, -0.2860, -0.3572, -0.3082, -0.2523, -0.3716, -0.1746,\n",
      "        -0.3501, -0.2798, -0.4147, -0.3324, -0.0460, -0.3945, -0.1980, -0.2400,\n",
      "        -0.3523, -0.2701, -0.2415, -0.4153, -0.3179, -0.3848, -0.2700, -0.2704,\n",
      "        -0.3436, -0.4270, -0.4149, -0.1278, -0.4004, -0.1576, -0.2709, -0.2414,\n",
      "        -0.3225, -0.3507, -0.4555, -0.2720, -0.2572, -0.2826, -0.4174, -0.3060,\n",
      "        -0.3433, -0.4817, -0.3958, -0.2979, -0.3573, -0.2900, -0.2611, -0.4648,\n",
      "        -0.3926, -0.4141, -0.3241, -0.3840, -0.3565, -0.3188, -0.2950, -0.3629])\n",
      "Layer: model.1.running_mean, Shape: torch.Size([64])\n",
      "tensor([-0.0390, -0.0294, -0.1142,  0.0226,  0.0653, -0.0978, -0.1257,  0.0503,\n",
      "        -0.0701,  0.0208,  0.0497, -0.1403,  0.0247, -0.0236,  0.0265,  0.0197,\n",
      "        -0.0204,  0.0491, -0.0677,  0.1246, -0.1276, -0.0925,  0.0979, -0.0876,\n",
      "         0.0387, -0.0574, -0.1463, -0.0587, -0.0371, -0.0043,  0.1617, -0.1261,\n",
      "        -0.0701,  0.0494, -0.0903,  0.0501, -0.0371,  0.0781, -0.1297,  0.1060,\n",
      "         0.1572,  0.0478,  0.1127,  0.1096, -0.1172,  0.0229, -0.0207, -0.1341,\n",
      "        -0.0177,  0.0317, -0.0626, -0.1139,  0.0421, -0.1407,  0.0105,  0.1018,\n",
      "         0.0330, -0.0667, -0.0417,  0.0212, -0.0379,  0.0562, -0.1083,  0.0817])\n",
      "Layer: model.1.running_var, Shape: torch.Size([64])\n",
      "tensor([0.8340, 0.7416, 0.8749, 1.3085, 1.0492, 1.3355, 1.5453, 0.7515, 1.5730,\n",
      "        1.4234, 1.0311, 1.1412, 1.2620, 1.0431, 1.6414, 0.9068, 0.8937, 1.0451,\n",
      "        1.1870, 1.2331, 1.1706, 0.7714, 1.1142, 1.5610, 1.1088, 1.0101, 0.9077,\n",
      "        1.2906, 1.3784, 0.7913, 1.1378, 1.3428, 1.0635, 1.3385, 0.6831, 1.1616,\n",
      "        0.9205, 0.8337, 1.1977, 0.9297, 0.6966, 0.9424, 1.5459, 1.1737, 1.5086,\n",
      "        1.2651, 0.9930, 1.2333, 0.8331, 1.4144, 1.0888, 1.9898, 1.1782, 1.2653,\n",
      "        0.9580, 1.1649, 1.1574, 0.7685, 1.2689, 0.8703, 1.0084, 1.3280, 1.3040,\n",
      "        1.3474])\n",
      "Layer: model.1.num_batches_tracked, Shape: torch.Size([])\n",
      "tensor(8294)\n",
      "Layer: model.4.weight, Shape: torch.Size([32, 64])\n",
      "tensor([[ 0.0134,  0.1009, -0.1660,  ..., -0.1494,  0.0615,  0.1556],\n",
      "        [ 0.0717,  0.0802,  0.0630,  ..., -0.0640, -0.0704,  0.0764],\n",
      "        [ 0.0497, -0.2122,  0.0789,  ...,  0.1302,  0.0563, -0.0627],\n",
      "        ...,\n",
      "        [ 0.0307,  0.1496, -0.1271,  ..., -0.1742,  0.1619,  0.1119],\n",
      "        [ 0.1171, -0.0084, -0.0179,  ...,  0.0329, -0.0068,  0.2511],\n",
      "        [ 0.0849, -0.0078, -0.0877,  ..., -0.0865, -0.0744, -0.0533]])\n",
      "Layer: model.4.bias, Shape: torch.Size([32])\n",
      "tensor([-0.0616,  0.0312,  0.0749, -0.0131, -0.1020, -0.0007,  0.0289,  0.0673,\n",
      "         0.1067,  0.0141, -0.0321,  0.0164,  0.0984,  0.0978,  0.0732, -0.0960,\n",
      "        -0.0354, -0.0735, -0.0328, -0.0788, -0.1088, -0.0703, -0.0545, -0.0251,\n",
      "         0.1147, -0.1071,  0.0647,  0.0168, -0.0642,  0.0015,  0.0652, -0.0749])\n",
      "Layer: model.5.weight, Shape: torch.Size([32])\n",
      "tensor([1.2373, 1.2892, 1.1556, 1.2136, 1.2558, 0.9102, 1.1315, 1.0926, 1.1707,\n",
      "        1.1014, 1.1522, 1.1603, 1.1748, 1.1123, 1.2905, 1.2168, 1.1078, 1.2829,\n",
      "        1.2024, 1.1433, 1.2237, 1.2652, 1.2794, 1.3404, 1.1140, 1.2694, 1.0404,\n",
      "        1.1994, 1.2036, 1.0430, 1.0778, 1.1592])\n",
      "Layer: model.5.bias, Shape: torch.Size([32])\n",
      "tensor([ 0.1593,  0.1907,  0.2058,  0.1103,  0.1343, -0.0483,  0.1566,  0.1094,\n",
      "         0.0551,  0.1286,  0.0732,  0.1510,  0.1605,  0.0971,  0.1581,  0.1233,\n",
      "         0.0280,  0.1720,  0.0931,  0.0846,  0.1486,  0.1793,  0.1193,  0.1524,\n",
      "         0.0720,  0.1429,  0.0613,  0.0544,  0.1540,  0.0672,  0.0030,  0.1088])\n",
      "Layer: model.5.running_mean, Shape: torch.Size([32])\n",
      "tensor([-0.5000,  0.1753,  0.2611, -0.3269,  0.0255, -0.1402, -0.6411, -0.2813,\n",
      "        -0.4301, -0.2892, -0.6962, -0.3702, -0.5794, -0.5080, -0.0151, -0.0640,\n",
      "        -0.0588, -0.0590, -0.4270,  0.1957, -0.2403, -0.4121, -0.0905, -0.2316,\n",
      "        -0.4581, -0.0980, -0.3702, -0.2244, -0.1525, -0.5072, -0.1193, -0.6894])\n",
      "Layer: model.5.running_var, Shape: torch.Size([32])\n",
      "tensor([1.2233, 0.8268, 0.8458, 0.9837, 0.7205, 0.6306, 1.5480, 0.7429, 1.0806,\n",
      "        0.7634, 1.0481, 1.5395, 1.4253, 1.4798, 0.9757, 0.6130, 0.8858, 0.9675,\n",
      "        0.8193, 0.4862, 1.2496, 1.2624, 0.6192, 1.0858, 1.1520, 0.5459, 0.8245,\n",
      "        0.7792, 1.1292, 1.3745, 0.9105, 1.0419])\n",
      "Layer: model.5.num_batches_tracked, Shape: torch.Size([])\n",
      "tensor(8294)\n",
      "Layer: model.7.weight, Shape: torch.Size([2, 32])\n",
      "tensor([[ 0.3406, -0.0905, -0.0810, -0.2761, -0.2391,  0.1516,  0.1151,  0.2294,\n",
      "          0.2589,  0.2437,  0.1024,  0.1944,  0.1357,  0.1646, -0.2166, -0.1661,\n",
      "         -0.1325, -0.1645,  0.3289,  0.3015, -0.3352, -0.3269, -0.3020, -0.3759,\n",
      "          0.0811, -0.3006,  0.1000,  0.2153, -0.2493,  0.0786,  0.0689,  0.2290],\n",
      "        [-0.1058,  0.3767,  0.2646,  0.2290,  0.2583,  0.0813, -0.2281, -0.1547,\n",
      "         -0.0675, -0.1267, -0.2089, -0.1095, -0.1602, -0.0913,  0.1889,  0.2792,\n",
      "          0.1089,  0.2398, -0.1926, -0.2466,  0.0917,  0.3031,  0.2089,  0.1453,\n",
      "         -0.1643,  0.1526, -0.2234, -0.2815,  0.1931, -0.0917, -0.2255, -0.1311]])\n",
      "Layer: model.7.bias, Shape: torch.Size([2])\n",
      "tensor([-0.0470,  0.0137])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leo88\\AppData\\Local\\Temp\\ipykernel_44308\\3966373712.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = PhishingDetectionModel(input_size, hidden_size, output_size)\n",
    "\n",
    "# Load the saved weights\n",
    "model_path = \"best_model.pth\"  # Replace with your .pth file path\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# Access weights\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "# Print weights and biases\n",
    "for name, param in state_dict.items():\n",
    "    print(f\"Layer: {name}, Shape: {param.shape}\")\n",
    "    print(param)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
